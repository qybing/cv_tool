import os
import hashlib
import shutil
from concurrent.futures import ThreadPoolExecutor
from collections import defaultdict
import time
import imghdr

# ======== é…ç½®åŒºåŸŸ (æŒ‰éœ€ä¿®æ”¹è¿™äº›å˜é‡) ========
SOURCE_DIR = 'JPEGImages'  # è¦æ‰«æçš„æºç›®å½•è·¯å¾„
DUPLICATE_DIR = "images_duplicate"  # å¤‡ä»½ç›®å½•è·¯å¾„ï¼ˆé‡å¤æ–‡ä»¶å°†ç§»åˆ°è¿™é‡Œï¼‰
USE_FAST_HASH = True  # æ˜¯å¦ä½¿ç”¨å¿«é€Ÿå“ˆå¸Œæ¨¡å¼ (True/False)
MIN_FILE_SIZE = 4096  # æœ€å°å¤„ç†çš„å›¾ç‰‡å¤§å°(å­—èŠ‚)

import os
import hashlib
import shutil
from concurrent.futures import ThreadPoolExecutor
from collections import defaultdict
import imghdr
import time


# ======== é…ç½®åŒºåŸŸ ========
# SOURCE_DIR = "/path/to/your/image/folder"  # æºå›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
# DUPLICATE_DIR = "/path/to/duplicate/folder"  # é‡å¤æ–‡ä»¶ä¿å­˜è·¯å¾„
# USE_FAST_HASH = True  # ä½¿ç”¨å¿«é€Ÿå“ˆå¸Œæ¨¡å¼ (True/False)
# MIN_FILE_SIZE = 4096  # æœ€å°å¤„ç†çš„å›¾ç‰‡å¤§å°(å­—èŠ‚)


# =========================

def is_valid_image(file_path):
    """éªŒè¯æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆå›¾ç‰‡"""
    try:
        # éªŒè¯æ–‡ä»¶æ‰©å±•åå’Œå®é™…æ ¼å¼åŒ¹é…
        if imghdr.what(file_path) is None:
            return False
        # å¿«é€ŸéªŒè¯å›¾ç‰‡æ–‡ä»¶å¤´
        with open(file_path, 'rb') as f:
            header = f.read(16)
            return header.startswith(b'\xFF\xD8') or header.startswith(b'\x89PNG') or \
                header.startswith(b'GIF') or header.startswith(b'\x49\x49') or \
                header.startswith(b'MM')
    except (OSError, IOError):
        return False


def get_file_signature(file_path):
    """è·å–æ–‡ä»¶çš„å“ˆå¸Œç­¾åï¼ˆå¿«é€Ÿæ¨¡å¼æˆ–å®Œæ•´æ¨¡å¼ï¼‰"""
    # åˆ›å»ºè‡ªå®šä¹‰å“ˆå¸Œå¯¹è±¡ï¼ˆBLAKE2æ¯”MD5/SHAæ›´å¿«ï¼‰
    hasher = hashlib.blake2b(digest_size=16)

    if USE_FAST_HASH:
        # å¿«é€Ÿæ¨¡å¼ - é‡‡æ ·è¯»å–å…³é”®éƒ¨åˆ†
        size = os.path.getsize(file_path)
        with open(file_path, 'rb') as f:
            # æ–‡ä»¶å¼€å¤´
            hasher.update(f.read(4096))

            # æ–‡ä»¶ä¸­æ®µï¼ˆå¦‚æœæ–‡ä»¶è¶³å¤Ÿå¤§ï¼‰
            if size > 8192:
                f.seek(size // 2 - 2048)
                hasher.update(f.read(4096))

            # æ–‡ä»¶æœ«å°¾ï¼ˆå¦‚æœæ–‡ä»¶è¶³å¤Ÿå¤§ï¼‰
            if size > 12288:
                f.seek(-4096, 2)
                hasher.update(f.read(4096))
    else:
        # å®Œæ•´æ¨¡å¼ - é€å—è¯»å–æ•´ä¸ªæ–‡ä»¶
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(128 * 1024), b''):
                hasher.update(chunk)

    return hasher.hexdigest()


def find_image_duplicates():
    """æ‰«æç›®å½•å¹¶æŸ¥æ‰¾é‡å¤å›¾ç‰‡"""
    print(f"ğŸ“‚ å¼€å§‹æ‰«æå›¾ç‰‡ç›®å½•: {SOURCE_DIR}")
    start_time = time.time()

    # ç¬¬ä¸€æ­¥ï¼šæŒ‰å¤§å°é¢„åˆ†ç»„ï¼ˆå¿«é€Ÿç­›é€‰ï¼‰
    size_map = defaultdict(list)
    file_count = 0

    for root, _, files in os.walk(SOURCE_DIR):
        for name in files:
            path = os.path.join(root, name)
            if not os.path.isfile(path):
                continue

            try:
                size = os.path.getsize(path)
                if size < MIN_FILE_SIZE:
                    continue

                if not is_valid_image(path):
                    continue

                size_map[size].append(path)
                file_count += 1
            except OSError:
                continue

    print(f"ğŸ” å‘ç° {file_count} ä¸ªæœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶ï¼ˆå¤§å° > {MIN_FILE_SIZE} å­—èŠ‚ï¼‰")
    print(f"â± åˆå§‹æ‰«æè€—æ—¶: {time.time() - start_time:.2f} ç§’")

    # ç¬¬äºŒæ­¥ï¼šå¹¶è¡Œè®¡ç®—å“ˆå¸Œç­¾å
    print(f"ğŸ§® å¼€å§‹è®¡ç®—æ–‡ä»¶ç­¾åï¼ˆ{'å¿«é€Ÿæ¨¡å¼' if USE_FAST_HASH else 'å®Œæ•´æ¨¡å¼'}ï¼‰...")
    hash_map = defaultdict(list)
    with ThreadPoolExecutor(max_workers=os.cpu_count() * 2) as executor:
        futures = {}
        # åªå¤„ç†å¯èƒ½æœ‰é‡å¤çš„å¤§å°ç»„
        for size, paths in size_map.items():
            if len(paths) > 1:
                for path in paths:
                    futures[executor.submit(get_file_signature, path)] = path

        # æ”¶é›†ç»“æœ
        for i, future in enumerate(futures):
            try:
                path = futures[future]
                file_hash = future.result()
                hash_map[file_hash].append(path)

                if (i + 1) % 500 == 0:
                    print(f"ğŸ”„ å¤„ç†è¿›åº¦: {i + 1}/{len(futures)} ä¸ªæ–‡ä»¶")
            except Exception as e:
                print(f"âš ï¸ å¤„ç†å¤±è´¥ [{path}]: {str(e)}")

    # ç¬¬ä¸‰æ­¥ï¼šè¯†åˆ«é‡å¤é¡¹
    duplicates = {h: paths for h, paths in hash_map.items() if len(paths) > 1}

    print(f"âœ… å»é‡åˆ†æå®Œæˆï¼å‘ç° {len(duplicates)} ç»„é‡å¤å›¾ç‰‡")
    print(f"â± æ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’")
    return duplicates


def move_duplicate_files(duplicates):
    """ç§»åŠ¨é‡å¤æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•"""
    if not duplicates:
        print("ğŸ‰ æœªå‘ç°é‡å¤å›¾ç‰‡")
        return 0, 0

    print(f"ğŸšš å¼€å§‹ç§»åŠ¨é‡å¤æ–‡ä»¶åˆ°: {DUPLICATE_DIR}")
    os.makedirs(DUPLICATE_DIR, exist_ok=True)

    moved_count = 0
    space_freed = 0

    for file_hash, paths in duplicates.items():
        # æŒ‰è·¯å¾„æ’åºï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªï¼‰
        paths.sort()
        keep_file = paths[0]
        move_files = paths[1:]

        for src_path in move_files:
            try:
                # åœ¨ç›®æ ‡ä½ç½®ä¿æŒç›¸åŒç›®å½•ç»“æ„
                rel_path = os.path.relpath(src_path, SOURCE_DIR)
                dest_path = os.path.join(DUPLICATE_DIR, rel_path)
                dest_dir = os.path.dirname(dest_path)

                # åˆ›å»ºç›®æ ‡ç›®å½•
                os.makedirs(dest_dir, exist_ok=True)

                # å¤„ç†æ–‡ä»¶åå†²çª
                if os.path.exists(dest_path):
                    base, ext = os.path.splitext(dest_path)
                    counter = 1
                    while os.path.exists(f"{base}_{counter}{ext}"):
                        counter += 1
                    dest_path = f"{base}_{counter}{ext}"

                # è·å–æ–‡ä»¶å¤§å°å¹¶ç§»åŠ¨
                file_size = os.path.getsize(src_path)
                shutil.move(src_path, dest_path)

                moved_count += 1
                space_freed += file_size

                # è¿›åº¦æŠ¥å‘Š
                if moved_count % 100 == 0:
                    print(f"ğŸ“¦ å·²ç§»åŠ¨ {moved_count} ä¸ªæ–‡ä»¶ | é‡Šæ”¾ç©ºé—´: {space_freed / 1024 / 1024:.2f} MB")

            except Exception as e:
                print(f"âŒ ç§»åŠ¨å¤±è´¥ [{src_path}]: {str(e)}")

    return moved_count, space_freed


def main():
    print("\n" + "=" * 50)
    print(f"ğŸ–¼ï¸ å›¾ç‰‡å»é‡å·¥å…· | æºç›®å½•: {SOURCE_DIR}")
    print("=" * 50 + "\n")

    start_time = time.time()

    # æŸ¥æ‰¾é‡å¤é¡¹
    duplicates = find_image_duplicates()

    # ç§»åŠ¨é‡å¤æ–‡ä»¶
    move_start = time.time()
    moved_count, space_freed = move_duplicate_files(duplicates)
    move_time = time.time() - move_start

    # ç»“æœæ±‡æ€»
    total_time = time.time() - start_time

    print("\n" + "=" * 50)
    print("âœ¨ æ“ä½œå®Œæˆï¼ç»“æœæ±‡æ€»")
    print("=" * 50)
    print(f"ğŸ”¸ å‘ç°é‡å¤ç»„: {len(duplicates)} ç»„")
    print(f"ğŸ”¸ ç§»åŠ¨æ–‡ä»¶æ•°: {moved_count} ä¸ª")
    print(f"ğŸ”¸ é‡Šæ”¾ç©ºé—´: {space_freed / 1024 / 1024:.2f} MB")
    print(f"ğŸ”¸ ç§»åŠ¨è€—æ—¶: {move_time:.2f} ç§’")
    print(f"ğŸ”¸ æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"ğŸ”¸ é‡å¤æ–‡ä»¶ä½ç½®: {DUPLICATE_DIR}")

    if moved_count > 0:
        print("\nğŸ’¡ æç¤º: è¯·æ£€æŸ¥é‡å¤æ–‡ä»¶ç›®å½•ç¡®è®¤æ— è¯¯åï¼Œå¯å®‰å…¨åˆ é™¤")


def create_dir(file_path):
    if not os.path.isdir(file_path):
        os.makedirs(file_path)
    else:
        # åˆ é™¤æ–‡ä»¶å¤¹åŠå…¶å†…å®¹
        shutil.rmtree(file_path)
        # é‡æ–°åˆ›å»ºç©ºæ–‡ä»¶å¤¹
        os.makedirs(file_path)


def file_move3():
    img_duplicate_dir = 'JPEGImages_duplicate'
    src_xml_dir = r'VOC/Annotations'
    xml_duplicate_dir = r'VOC/Annotations_duplicate'
    create_dir(xml_duplicate_dir)
    img_dict = {}
    img_duplicate_list = os.listdir(img_duplicate_dir)
    src_xml_dir_list = os.listdir(src_xml_dir)
    for img_name in img_duplicate_list:
        img_prefix = os.path.splitext(img_name)
        img_dict[img_prefix[0]] = img_name
    move_count = 0
    for xml_name in src_xml_dir_list:
        xml_prefix = os.path.splitext(xml_name)
        if xml_prefix[0] in img_dict:
            src_xml_path = os.path.join(src_xml_dir,xml_name)
            save_xml_path = os.path.join(xml_duplicate_dir,xml_name)
            shutil.move(src_xml_path,save_xml_path)
            move_count+=1
    print(f"é‡å¤çš„å›¾ç‰‡æœ‰:{len(img_duplicate_list)},ç§»åŠ¨çš„xmlæœ‰:{move_count}")
    




if __name__ == "__main__":
    main()
